{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc933320-e8e2-4f8f-8296-3955775bb8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loaded 3019 sentences.\n",
      "Class balance: [1283 1736]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training base DistilBERT classifier...\n",
      "[Base] Epoch 1/3 - loss: 0.6811\n",
      "Base validation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.500     0.031     0.059       128\n",
      "           1      0.578     0.977     0.726       174\n",
      "\n",
      "    accuracy                          0.576       302\n",
      "   macro avg      0.539     0.504     0.393       302\n",
      "weighted avg      0.545     0.576     0.444       302\n",
      "\n",
      "[Base] Epoch 2/3 - loss: 0.6209\n",
      "Base validation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.518     0.555     0.536       128\n",
      "           1      0.655     0.621     0.637       174\n",
      "\n",
      "    accuracy                          0.593       302\n",
      "   macro avg      0.586     0.588     0.587       302\n",
      "weighted avg      0.597     0.593     0.594       302\n",
      "\n",
      "[Base] Epoch 3/3 - loss: 0.4061\n",
      "Base validation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.528     0.508     0.518       128\n",
      "           1      0.648     0.667     0.657       174\n",
      "\n",
      "    accuracy                          0.599       302\n",
      "   macro avg      0.588     0.587     0.588       302\n",
      "weighted avg      0.597     0.599     0.598       302\n",
      "\n",
      "Done training base model.\n",
      "Loading spaCy model...\n",
      "Parsing sentences with spaCy...\n",
      "Using 16 masking-based concepts (roles).\n",
      "Computing base probabilities on full sentences...\n",
      "Building masked sentences and computing concept values...\n",
      "  Role 1/16...\n",
      "  Role 2/16...\n",
      "  Role 3/16...\n",
      "  Role 4/16...\n",
      "  Role 5/16...\n",
      "  Role 6/16...\n",
      "  Role 7/16...\n",
      "  Role 8/16...\n",
      "  Role 9/16...\n",
      "  Role 10/16...\n",
      "  Role 11/16...\n",
      "  Role 12/16...\n",
      "  Role 13/16...\n",
      "  Role 14/16...\n",
      "  Role 15/16...\n",
      "  Role 16/16...\n",
      "Concept matrix shape: (3019, 16)\n",
      "Computing sentence representations for θ-network...\n",
      "Sentence reps shape: (3019, 768)\n",
      "Training DIRECT-CONCEPT SENN with 5-fold cross-validation...\n",
      "\n",
      "=== Fold 1 ===\n",
      "\n",
      "=== Fold 2 ===\n",
      "\n",
      "=== Fold 3 ===\n",
      "\n",
      "=== Fold 4 ===\n",
      "\n",
      "=== Fold 5 ===\n",
      "\n",
      "=== OOF Metrics for DIRECT-CONCEPT SENN (5-fold CV) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.828     0.890     0.858      1283\n",
      "           1      0.914     0.863     0.888      1736\n",
      "\n",
      "    accuracy                          0.874      3019\n",
      "   macro avg      0.871     0.877     0.873      3019\n",
      "weighted avg      0.877     0.874     0.875      3019\n",
      "\n",
      "Accuracy: 0.8744617422987744\n",
      "ROC-AUC: 0.9195030009590138\n",
      "Confusion matrix:\n",
      "[[1142  141]\n",
      " [ 238 1498]]\n",
      "0: SubjectNP\n",
      "1: ObjectNP\n",
      "2: VerbPhrase\n",
      "3: AdjunctPP\n",
      "4: AdjunctAdvP\n",
      "5: AdjectivePhrases\n",
      "6: NounModifiers\n",
      "7: AuxVerbs\n",
      "8: RelativeClause\n",
      "9: ConjunctionPhrases\n",
      "10: Pronouns\n",
      "11: Intensifiers\n",
      "12: VerbParticles\n",
      "13: DirectionalAdverbs\n",
      "14: PleonasticSubjects\n",
      "15: ClauseFinalAdjunct\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import spacy\n",
    "from transformers import (\n",
    "    DistilBertTokenizerFast,\n",
    "    DistilBertForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# CONFIG\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "BASE_MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "BASE_EPOCHS = 3      # for DistilBERT\n",
    "SENN_EPOCHS = 40     # for SENN\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 0. Load data (SPC.json)\n",
    "# -------------------------------------------------------------\n",
    "df = pd.read_json(f'SPC.json', lines=True)\n",
    "sentences = []\n",
    "labels = []\n",
    "for _, row in df.iterrows():\n",
    "    sent = f\"{row['before']} {row['first']} {row['second']} {row['after']}\"\n",
    "    sent = \" \".join(sent.split())\n",
    "    label = 0 if row[\"consensus\"] == \"neither\" else 1\n",
    "    sentences.append(sent)\n",
    "    labels.append(label)\n",
    "    consensus_labels = df[\"consensus\"].values  # e.g. \"neither\", \"first\", \"second\", maybe \"both\"\n",
    "\n",
    "\n",
    "sentences = np.array(sentences)\n",
    "labels = np.array(labels, dtype=np.int64)\n",
    "\n",
    "print(f\"Loaded {len(sentences)} sentences.\")\n",
    "print(\"Class balance:\", np.bincount(labels))\n",
    "# -------------------------------------------------------------\n",
    "# 1. Train base DistilBERT classifier\n",
    "# -------------------------------------------------------------\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(BASE_MODEL_NAME)\n",
    "\n",
    "class PleonasmDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = list(labels)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text  = self.texts[idx]\n",
    "        label = int(self.labels[idx])\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
    "        item[\"labels\"] = torch.tensor(label, dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# Train/val split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    sentences, labels, test_size=0.1, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "train_ds = PleonasmDataset(train_texts, train_labels, tokenizer, MAX_LEN)\n",
    "val_ds   = PleonasmDataset(val_texts,   val_labels,   tokenizer, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "base_model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    BASE_MODEL_NAME, num_labels=2\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = AdamW(base_model.parameters(), lr=2e-5)\n",
    "total_steps = len(train_loader) * BASE_EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.1 * total_steps),\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "def train_base_model():\n",
    "    base_model.train()\n",
    "    for epoch in range(BASE_EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            outputs = base_model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"[Base] Epoch {epoch+1}/{BASE_EPOCHS} - loss: {avg_loss:.4f}\")\n",
    "        eval_base_model()\n",
    "\n",
    "def eval_base_model():\n",
    "    base_model.eval()\n",
    "    preds = []\n",
    "    true  = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            labels_b = batch[\"labels\"].numpy()\n",
    "            true.extend(labels_b)\n",
    "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "            outputs = base_model(**batch)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=-1)[:, 1]\n",
    "            pred_labels = (probs > 0.5).long().cpu().numpy()\n",
    "            preds.extend(pred_labels)\n",
    "    print(\"Base validation report:\")\n",
    "    print(classification_report(true, preds, digits=3))\n",
    "\n",
    "print(\"Training base DistilBERT classifier...\")\n",
    "train_base_model()\n",
    "print(\"Done training base model.\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2. spaCy parsing and role extraction\n",
    "# -------------------------------------------------------------\n",
    "print(\"Loading spaCy model...\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "INTENSIFIERS = {\n",
    "    \"very\", \"extremely\", \"totally\", \"utterly\", \"completely\",\n",
    "    \"absolutely\", \"really\", \"quite\", \"so\", \"highly\", \"fully\"\n",
    "}\n",
    "NEGATION_LEMMAS = {\"not\", \"no\", \"never\"}\n",
    "TIME_LEMMAS = {\"yesterday\", \"today\", \"tomorrow\", \"now\", \"recently\", \"currently\", \"tonight\"}\n",
    "DIRECTION_ADVERBS = {\n",
    "    \"back\", \"forward\", \"ahead\", \"around\", \"away\", \"together\",\n",
    "    \"down\", \"up\", \"out\", \"in\", \"off\", \"over\", \"across\"\n",
    "}\n",
    "\n",
    "PLEONASTIC_SUBJECT_LEMMAS = {\"it\", \"there\"}\n",
    "\n",
    "def in_root_clause(tok, root):\n",
    "    \"\"\"Check if tok is in the clause dominated by root.\"\"\"\n",
    "    cur = tok\n",
    "    while cur.head != cur:\n",
    "        if cur == root:\n",
    "            return True\n",
    "        cur = cur.head\n",
    "    return False\n",
    "\n",
    "def root_index(doc):\n",
    "    for i, t in enumerate(doc):\n",
    "        if t.dep_ == \"ROOT\":\n",
    "            return i\n",
    "    return 0\n",
    "\n",
    "def extract_role_token_sets(doc):\n",
    "    \"\"\"\n",
    "    Return:\n",
    "      - roles: list of sets of token indices for 16 roles\n",
    "      - core_roles: dict with 'subj','verb','obj','adjunct' sets\n",
    "\n",
    "    Roles (16):\n",
    "      0) Subject NP\n",
    "      1) Object NP\n",
    "      2) VerbPhrase (Option A: ROOT verb + aux/auxpass/advmod/neg)\n",
    "      3) AdjunctPP          (prep)\n",
    "      4) AdjunctAdvP        (advmod)\n",
    "      5) AdjectivePhrases   (amod, acomp)\n",
    "      6) NounModifiers      (det, poss, nummod)\n",
    "      7) AuxVerbs           (aux, auxpass)\n",
    "      8) RelativeClause     (relcl)\n",
    "      9) ConjunctionPhrases (conj subtree)\n",
    "     10) Pronouns\n",
    "     11) Intensifiers\n",
    "\n",
    "     12) VerbParticles        (dep_ == \"prt\" in root clause)\n",
    "     13) DirectionalAdverbs   (ADV with lemma in DIRECTION_ADVERBS)\n",
    "     14) PleonasticSubjects   (\"it\"/\"there\" as expl/nsubj in root clause)\n",
    "     15) ClauseFinalAdjunct   (rightmost advmod/prep subtree in root clause)\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- 16 slots instead of 12 ----\n",
    "    roles = [set() for _ in range(16)]\n",
    "    ridx = root_index(doc)\n",
    "    root = doc[ridx]\n",
    "\n",
    "    def subtree_indices(tok):\n",
    "        return {t.i for t in tok.subtree}\n",
    "\n",
    "    subj_tokens    = set()\n",
    "    obj_tokens     = set()\n",
    "    adjunct_tokens = set()\n",
    "    verb_tokens    = set()  # Option A\n",
    "\n",
    "    # --- Pass 1: gather subjects, objects, adjuncts (root clause) ---\n",
    "    for t in doc:\n",
    "        # subjects in root clause\n",
    "        if t.dep_ in (\"nsubj\", \"csubj\", \"nsubjpass\") and in_root_clause(t, root):\n",
    "            subj_tokens.update(subtree_indices(t))\n",
    "\n",
    "        # objects in root clause\n",
    "        if t.dep_ in (\"dobj\", \"attr\", \"oprd\", \"pobj\") and in_root_clause(t, root):\n",
    "            obj_tokens.update(subtree_indices(t))\n",
    "\n",
    "        # generic adjuncts (prep/advmod) in root clause\n",
    "        if t.dep_ in (\"prep\", \"advmod\") and in_root_clause(t, root):\n",
    "            adjunct_tokens.update(subtree_indices(t))\n",
    "\n",
    "    core_roles = {\n",
    "        \"subj\":    subj_tokens,\n",
    "        \"verb\":    set(),\n",
    "        \"obj\":     obj_tokens,\n",
    "        \"adjunct\": adjunct_tokens,\n",
    "    }\n",
    "\n",
    "    # 0) Subject NP\n",
    "    roles[0].update(subj_tokens)\n",
    "\n",
    "    # 1) Object NP\n",
    "    roles[1].update(obj_tokens)\n",
    "\n",
    "    # 2) Verb phrase (Option A: ROOT + aux/auxpass/advmod/neg)\n",
    "    verb_tokens.add(root.i)\n",
    "    for t in doc:\n",
    "        if t.head == root and t.dep_ in (\"aux\", \"auxpass\", \"advmod\", \"neg\"):\n",
    "            verb_tokens.add(t.i)\n",
    "    roles[2].update(verb_tokens)\n",
    "    core_roles[\"verb\"] = verb_tokens\n",
    "\n",
    "    # 3) Adjunct PP (prep subtrees in root clause)\n",
    "    for t in doc:\n",
    "        if t.dep_ == \"prep\" and in_root_clause(t, root):\n",
    "            roles[3].update(subtree_indices(t))\n",
    "\n",
    "    # 4) Adjunct AdvP (advmod subtrees in root clause)\n",
    "    for t in doc:\n",
    "        if t.dep_ == \"advmod\" and in_root_clause(t, root):\n",
    "            roles[4].update(subtree_indices(t))\n",
    "\n",
    "    # 5) Adjective phrases (ADJ with amod/acomp)\n",
    "    for t in doc:\n",
    "        if t.pos_ == \"ADJ\" and t.dep_ in (\"amod\", \"acomp\"):\n",
    "            roles[5].update(subtree_indices(t))\n",
    "\n",
    "    # 6) Noun modifiers (det, nummod, poss)\n",
    "    for t in doc:\n",
    "        if t.dep_ in (\"det\", \"nummod\", \"poss\"):\n",
    "            roles[6].add(t.i)\n",
    "\n",
    "    # 7) Auxiliary verbs (aux, auxpass) in root clause\n",
    "    for t in doc:\n",
    "        if t.dep_ in (\"aux\", \"auxpass\") and in_root_clause(t, root):\n",
    "            roles[7].add(t.i)\n",
    "\n",
    "    # 8) Relative clause (relcl subtrees)\n",
    "    for t in doc:\n",
    "        if t.dep_ == \"relcl\":\n",
    "            roles[8].update(subtree_indices(t))\n",
    "\n",
    "    # 9) Conjunction phrases (conj subtrees)\n",
    "    for t in doc:\n",
    "        if t.dep_ == \"conj\":\n",
    "            roles[9].update(subtree_indices(t))\n",
    "\n",
    "    # 10) Pronouns\n",
    "    for t in doc:\n",
    "        if t.pos_ == \"PRON\":\n",
    "            roles[10].add(t.i)\n",
    "\n",
    "    # 11) Intensifiers (by lemma)\n",
    "    for t in doc:\n",
    "        if t.lemma_.lower() in INTENSIFIERS:\n",
    "            roles[11].add(t.i)\n",
    "\n",
    "    # 12) VerbParticles (phrasal verb particles) in root clause\n",
    "    for t in doc:\n",
    "        if t.dep_ == \"prt\" and in_root_clause(t, root):\n",
    "            roles[12].add(t.i)\n",
    "\n",
    "    # 13) DirectionalAdverbs (again, back, forward, up, down, etc.)\n",
    "    for t in doc:\n",
    "        if t.pos_ == \"ADV\" and t.lemma_.lower() in DIRECTION_ADVERBS:\n",
    "            roles[13].add(t.i)\n",
    "\n",
    "    # 14) PleonasticSubjects (\"it\"/\"there\" as expl or nsubj in root clause)\n",
    "    for t in doc:\n",
    "        lemma = t.lemma_.lower()\n",
    "        if in_root_clause(t, root):\n",
    "            if t.dep_ == \"expl\":\n",
    "                roles[14].add(t.i)\n",
    "            elif lemma in PLEONASTIC_SUBJECT_LEMMAS and t.dep_ in (\"nsubj\", \"expl\"):\n",
    "                roles[14].add(t.i)\n",
    "\n",
    "    # 15) ClauseFinalAdjunct (rightmost advmod/prep subtree in root clause)\n",
    "    last_adj_idx = None\n",
    "    for t in doc:\n",
    "        if t.dep_ in (\"advmod\", \"prep\") and in_root_clause(t, root):\n",
    "            if last_adj_idx is None or t.i > last_adj_idx:\n",
    "                last_adj_idx = t.i\n",
    "    if last_adj_idx is not None:\n",
    "        roles[15].update(subtree_indices(doc[last_adj_idx]))\n",
    "\n",
    "    return roles, core_roles\n",
    "\n",
    "\n",
    "print(\"Parsing sentences with spaCy...\")\n",
    "docs = list(nlp.pipe([str(s) for s in sentences], batch_size=64))\n",
    "\n",
    "all_roles = []\n",
    "for doc in docs:\n",
    "    role_sets, _ = extract_role_token_sets(doc)\n",
    "    all_roles.append(role_sets)\n",
    "\n",
    "K = len(all_roles[0])  # number of roles/concepts\n",
    "print(f\"Using {K} masking-based concepts (roles).\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3. Helper: base model prediction (probabilities) + sentence reps\n",
    "# -------------------------------------------------------------\n",
    "def base_predict_proba(texts, batch_size=32):\n",
    "    \"\"\"Return np.array of shape (N,) with P(y=1|x) from base_model.\"\"\"\n",
    "    base_model.eval()\n",
    "    probs_all = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            enc = tokenizer(\n",
    "                list(batch_texts),\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=MAX_LEN,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(DEVICE)\n",
    "            outputs = base_model(**enc)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=-1)[:, 1]\n",
    "            probs_all.append(probs.cpu().numpy())\n",
    "    return np.concatenate(probs_all, axis=0)\n",
    "\n",
    "def base_sentence_reps(texts, batch_size=32):\n",
    "    \"\"\"Return np.array (N, H) with hidden CLS representations from base_model.\"\"\"\n",
    "    base_model.eval()\n",
    "    reps_all = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch_texts = texts[i:i+batch_size]\n",
    "            enc = tokenizer(\n",
    "                list(batch_texts),\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=MAX_LEN,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(DEVICE)\n",
    "            outputs = base_model.distilbert(**{k: enc[k] for k in [\"input_ids\",\"attention_mask\"]})\n",
    "            # CLS token representation: first token of last_hidden_state\n",
    "            cls_rep = outputs.last_hidden_state[:, 0, :]  # (B, H)\n",
    "            reps_all.append(cls_rep.cpu().numpy())\n",
    "    return np.concatenate(reps_all, axis=0)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4. Build masking-based concepts\n",
    "# -------------------------------------------------------------\n",
    "def mask_sentence_by_role(doc, idx_set):\n",
    "    \"\"\"\n",
    "    Replace tokens in idx_set by [MASK].\n",
    "    Return reconstructed string.\n",
    "    \"\"\"\n",
    "    if not idx_set:\n",
    "        return doc.text\n",
    "    tokens = []\n",
    "    for i, t in enumerate(doc):\n",
    "        if i in idx_set:\n",
    "            tokens.append(\"[MASK]\")\n",
    "        else:\n",
    "            tokens.append(t.text)\n",
    "    sent = \" \".join(tokens)\n",
    "    return \" \".join(sent.split())\n",
    "\n",
    "print(\"Computing base probabilities on full sentences...\")\n",
    "s_full = base_predict_proba(sentences)  # shape (N,)\n",
    "\n",
    "print(\"Building masked sentences and computing concept values...\")\n",
    "concept_matrix = np.zeros((len(sentences), K), dtype=np.float32)\n",
    "\n",
    "# For each role k, mask that role in every sentence and compute s_masked\n",
    "for k in range(K):\n",
    "    print(f\"  Role {k+1}/{K}...\")\n",
    "    masked_texts = []\n",
    "    for doc, role_sets in zip(docs, all_roles):\n",
    "        idx_set = role_sets[k]\n",
    "        masked_texts.append(mask_sentence_by_role(doc, idx_set))\n",
    "    s_masked = base_predict_proba(masked_texts)\n",
    "    c_k = s_full - s_masked  # importance of that role\n",
    "    concept_matrix[:, k] = c_k\n",
    "\n",
    "print(\"Concept matrix shape:\", concept_matrix.shape)\n",
    "\n",
    "# Sentence representations for θ-network\n",
    "print(\"Computing sentence representations for θ-network...\")\n",
    "sent_reps = base_sentence_reps(sentences)  # (N, H)\n",
    "print(\"Sentence reps shape:\", sent_reps.shape)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5. SENN model on masking-based concepts\n",
    "# -------------------------------------------------------------\n",
    "class SENNDirectConcept(nn.Module):\n",
    "    \"\"\"\n",
    "    Simpler SENN-style model:\n",
    "      - concepts c(x) are used directly (no concept_net, no h ≠ c)\n",
    "      - θ(x) is still learned from the sentence representation\n",
    "      - prediction: f(x) = sum_k c_k(x) * θ_k(x) + b\n",
    "    \"\"\"\n",
    "    def __init__(self, concept_dim, sent_dim,\n",
    "                 theta_hidden=64,\n",
    "                 nonneg_theta=True, normalize_theta=False):\n",
    "        super().__init__()\n",
    "        self.K = concept_dim\n",
    "        self.nonneg_theta = nonneg_theta\n",
    "        self.normalize_theta = normalize_theta\n",
    "\n",
    "        # only theta_net, no concept_net\n",
    "        self.theta_net = nn.Sequential(\n",
    "            nn.Linear(sent_dim, theta_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(theta_hidden, concept_dim),\n",
    "        )\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def theta(self, sent_vec):\n",
    "        th = self.theta_net(sent_vec)      # (B, K)\n",
    "        if self.nonneg_theta:\n",
    "            th = F.softplus(th)            # enforce θ_k >= 0\n",
    "        if self.normalize_theta:\n",
    "            th = th / (th.sum(dim=1, keepdim=True) + 1e-8)\n",
    "        return th\n",
    "\n",
    "    def forward(self, cvec, sent_vec):\n",
    "        \"\"\"\n",
    "        cvec: (B, K) raw concept values (probability differences)\n",
    "        sent_vec: (B, H) DistilBERT CLS embeddings\n",
    "\n",
    "        returns:\n",
    "          logit: (B, 1)\n",
    "          h: here we just return cvec itself so that the rest of your pipeline\n",
    "             (which expects (logit, h, theta)) still works\n",
    "          theta: (B, K)\n",
    "        \"\"\"\n",
    "        th = self.theta(sent_vec)          # (B, K)\n",
    "        contrib = cvec * th                # (B, K)\n",
    "        logit = contrib.sum(dim=1, keepdim=True) + self.bias\n",
    "        # For compatibility with your existing code, we return cvec as \"h\"\n",
    "        return logit, cvec, th\n",
    "\n",
    "\n",
    "def stability_regularizer(cvec, logit, theta):\n",
    "    grad = torch.autograd.grad(\n",
    "        outputs=logit.sum(),\n",
    "        inputs=cvec,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    return F.mse_loss(grad, theta)\n",
    "\n",
    "lambda_stab = 1e-3\n",
    "lambda_l1   = 1e-4\n",
    "\n",
    "def fit_one_fold_direct(Xc_tr, Xs_tr, y_tr, Xc_te, Xs_te,\n",
    "                        epochs=40, lr=1e-3, weight_decay=1e-4,\n",
    "                        theta_hidden=64, seed=123):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    concept_dim = Xc_tr.shape[1]\n",
    "    sent_dim    = Xs_tr.shape[1]\n",
    "\n",
    "    model = SENNDirectConcept(concept_dim, sent_dim,\n",
    "                              theta_hidden=theta_hidden).to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    Xc_tr_t = torch.tensor(Xc_tr, dtype=torch.float32).to(DEVICE)\n",
    "    Xs_tr_t = torch.tensor(Xs_tr, dtype=torch.float32).to(DEVICE)\n",
    "    y_tr_t  = torch.tensor(y_tr.reshape(-1,1), dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "    Xc_te_t = torch.tensor(Xc_te, dtype=torch.float32).to(DEVICE)\n",
    "    Xs_te_t = torch.tensor(Xs_te, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        opt.zero_grad()\n",
    "        Xc_tr_t.requires_grad_(True)\n",
    "\n",
    "        logit, h, theta = model(Xc_tr_t, Xs_tr_t)   # here h == cvec\n",
    "        bce  = F.binary_cross_entropy_with_logits(logit, y_tr_t)\n",
    "        stab = stability_regularizer(Xc_tr_t, logit, theta)\n",
    "        l1   = theta.abs().mean()\n",
    "        loss = bce + lambda_stab * stab + lambda_l1 * l1\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    # predict on this fold's test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logit_te, h_te, theta_te = model(Xc_te_t, Xs_te_t)\n",
    "        prob_te  = torch.sigmoid(logit_te).cpu().numpy().squeeze()\n",
    "        theta_te = theta_te.cpu().numpy()\n",
    "        h_te     = h_te.cpu().numpy()   # here h_te == Xc_te\n",
    "\n",
    "    return prob_te, theta_te, h_te, model\n",
    "\n",
    "X_c = concept_matrix\n",
    "X_s = sent_reps\n",
    "y   = labels\n",
    "N   = len(y)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "oof_prob  = np.zeros(N, dtype=np.float32)\n",
    "oof_theta = np.zeros((N, X_c.shape[1]), dtype=np.float32)\n",
    "oof_h     = np.zeros((N, X_c.shape[1]), dtype=np.float32)\n",
    "\n",
    "print(\"Training DIRECT-CONCEPT SENN with 5-fold cross-validation...\")\n",
    "for fold_idx, (tr_idx, te_idx) in enumerate(cv.split(X_c, y), start=1):\n",
    "    print(f\"\\n=== Fold {fold_idx} ===\")\n",
    "    Xc_tr, Xc_te = X_c[tr_idx], X_c[te_idx]\n",
    "    Xs_tr, Xs_te = X_s[tr_idx], X_s[te_idx]\n",
    "    y_tr,  y_te  = y[tr_idx],  y[te_idx]\n",
    "\n",
    "    prob_te, theta_te, h_te, _ = fit_one_fold_direct(\n",
    "        Xc_tr, Xs_tr, y_tr, Xc_te, Xs_te,\n",
    "        epochs=SENN_EPOCHS, lr=1e-3, weight_decay=1e-4,\n",
    "        theta_hidden=64,\n",
    "        seed=123 + fold_idx\n",
    "    )\n",
    "\n",
    "    oof_prob[te_idx]  = prob_te\n",
    "    oof_theta[te_idx] = theta_te\n",
    "    oof_h[te_idx]     = h_te   # note: this equals Xc_te\n",
    "\n",
    "print(\"\\n=== OOF Metrics for DIRECT-CONCEPT SENN (5-fold CV) ===\")\n",
    "y_pred_oof = (oof_prob >= 0.5).astype(int)\n",
    "print(classification_report(y, y_pred_oof, digits=3))\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred_oof))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y, oof_prob))\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y, y_pred_oof))\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6. Evaluate SENN on full dataset\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "role_names = [\n",
    "    \"SubjectNP\",           # 0\n",
    "    \"ObjectNP\",            # 1\n",
    "    \"VerbPhrase\",          # 2\n",
    "    \"AdjunctPP\",           # 3\n",
    "    \"AdjunctAdvP\",         # 4\n",
    "    \"AdjectivePhrases\",    # 5\n",
    "    \"NounModifiers\",       # 6\n",
    "    \"AuxVerbs\",            # 7\n",
    "    \"RelativeClause\",      # 8\n",
    "    \"ConjunctionPhrases\",  # 9\n",
    "    \"Pronouns\",            #10\n",
    "    \"Intensifiers\",        #11\n",
    "    \"VerbParticles\",       #12  <-- NEW\n",
    "    \"DirectionalAdverbs\",  #13  <-- NEW\n",
    "    \"PleonasticSubjects\",  #14  <-- NEW\n",
    "    \"ClauseFinalAdjunct\"   #15  <-- NEW\n",
    "]\n",
    "\n",
    "for i, name in enumerate(role_names):\n",
    "    print(f\"{i}: {name}\")\n",
    "\n",
    "# Optionally save SENN\n",
    "#torch.save(senn.state_dict(), HERE / \"senn_masking_concepts.pt\")\n",
    "#print(\"\\nSaved SENN model as senn_masking_concepts.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fb6f818-d775-444b-b765-a98593b4e9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pleonasm-word label accuracy vs consensus: 0.631\n",
      "Correct word-level hits: 1904 / 3019\n",
      "================================================================================\n",
      "Sentence 5: Always smiling cheerful and happy to do her job .\n",
      "Gold consensus: cheerful\n",
      "SENN prob: 0.823  → pred label: 1\n",
      "Gold tokens: {'cheerful'}\n",
      "Predicted tokens: {'smiling', 'always', 'cheerful'}\n",
      "\n",
      "Top concept contributions (c_k * θ_k):\n",
      "  k= 2 (        VerbPhrase)  contrib=+1.3366  span=['Always', 'smiling', 'cheerful']\n",
      "  k=10 (          Pronouns)  contrib=+0.0705  span=['her']\n",
      "  k= 6 (     NounModifiers)  contrib=+0.0600  span=['her']\n",
      "  k= 9 (ConjunctionPhrases)  contrib=+0.0401  span=['happy', 'to', 'do', 'her', 'job']\n",
      "  k= 0 (         SubjectNP)  contrib=+0.0000  span=[]\n",
      "================================================================================\n",
      "Sentence 54: That is what we are , unimportant little pets , cute little luggage for our women to tote around and poke when it tickles their fancy .\n",
      "Gold consensus: little\n",
      "SENN prob: 0.966  → pred label: 1\n",
      "Gold tokens: {'little'}\n",
      "Predicted tokens: {'unimportant', 'little'}\n",
      "\n",
      "Top concept contributions (c_k * θ_k):\n",
      "  k= 5 (  AdjectivePhrases)  contrib=+2.2339  span=['unimportant', 'little', 'little']\n",
      "  k= 2 (        VerbPhrase)  contrib=+0.6671  span=['is']\n",
      "  k= 9 (ConjunctionPhrases)  contrib=+0.1701  span=['poke']\n",
      "  k=10 (          Pronouns)  contrib=+0.1359  span=['That', 'what', 'we', 'our', 'it', 'their']\n",
      "  k= 6 (     NounModifiers)  contrib=+0.1138  span=['our', 'their']\n"
     ]
    }
   ],
   "source": [
    "# Gold labels: df['consensus'] is either \"neither\" or the pleonasm string\n",
    "consensus_labels = df[\"consensus\"].astype(str).values  # shape (N,)\n",
    "\n",
    "def get_gold_label_tokens(i: int):\n",
    "    \"\"\"\n",
    "    Gold pleonasm 'label tokens' for sentence i.\n",
    "\n",
    "    - If consensus == \"neither\" => {\"neither\"}\n",
    "    - Else => whitespace-tokenized words of that consensus string (lowercased)\n",
    "    \"\"\"\n",
    "    c = consensus_labels[i].strip().lower()\n",
    "    if c == \"neither\":\n",
    "        return {\"neither\"}\n",
    "    gold_tokens = set()\n",
    "    for w in c.split():\n",
    "        w = w.strip()\n",
    "        if w:\n",
    "            gold_tokens.add(w.lower())\n",
    "    return gold_tokens\n",
    "def get_predicted_label_tokens(i: int, top_m: int = 3):\n",
    "    \"\"\"\n",
    "    Predicted pleonasm label tokens for sentence i.\n",
    "\n",
    "    - If SENN predicts no pleonasm (y_pred_oof[i] == 0) => {\"neither\"}\n",
    "    - If SENN predicts pleonasm (1):\n",
    "        * contrib_k = c_k(x) * θ_k(x)\n",
    "        * keep only k with contrib_k > 0 and non-empty role span\n",
    "        * pick top_m concepts by contrib_k\n",
    "        * collect their tokens (lowercased) as predicted pleonasm words\n",
    "    \"\"\"\n",
    "    # Case 1: predicted no pleonasm\n",
    "    if y_pred_oof[i] == 0:\n",
    "        return {\"neither\"}\n",
    "\n",
    "    # Case 2: predicted pleonasm\n",
    "    c_vec   = concept_matrix[i]      # (K,) raw concept values\n",
    "    theta_i = oof_theta[i]           # (K,) relevance weights\n",
    "    contrib = c_vec * theta_i        # (K,)\n",
    "\n",
    "    # candidate concepts: positive contribution AND with at least one token\n",
    "    candidate_idx = [\n",
    "        k for k in range(len(contrib))\n",
    "        if contrib[k] > 0 and len(all_roles[i][k]) > 0\n",
    "    ]\n",
    "    if not candidate_idx:\n",
    "        # model says pleonasm but we don't have any positive-contrib span\n",
    "        return set()\n",
    "\n",
    "    # sort candidates by descending contribution\n",
    "    candidate_idx = sorted(candidate_idx, key=lambda k: -contrib[k])\n",
    "    top_concepts = candidate_idx[:top_m]\n",
    "\n",
    "    # collect tokens from top concepts\n",
    "    doc = docs[i]\n",
    "    tokens_out = set()\n",
    "    for k in top_concepts:\n",
    "        for j in all_roles[i][k]:\n",
    "            tokens_out.add(doc[j].text.lower())\n",
    "\n",
    "    return tokens_out\n",
    "correct = 0\n",
    "for i in range(N):\n",
    "    gold = get_gold_label_tokens(i)\n",
    "    pred = get_predicted_label_tokens(i, top_m=1)  # or 2/3 if you want\n",
    "\n",
    "    # A hit if there is any overlap between gold and predicted tokens\n",
    "    if gold & pred:\n",
    "        correct += 1\n",
    "\n",
    "pleonasm_word_acc = correct / N\n",
    "print(f\"\\nPleonasm-word label accuracy vs consensus: {pleonasm_word_acc:.3f}\")\n",
    "print(f\"Correct word-level hits: {correct} / {N}\")\n",
    "role_names = [\n",
    "    \"SubjectNP\",           # 0\n",
    "    \"ObjectNP\",            # 1\n",
    "    \"VerbPhrase\",          # 2\n",
    "    \"AdjunctPP\",           # 3\n",
    "    \"AdjunctAdvP\",         # 4\n",
    "    \"AdjectivePhrases\",    # 5\n",
    "    \"NounModifiers\",       # 6\n",
    "    \"AuxVerbs\",            # 7\n",
    "    \"RelativeClause\",      # 8\n",
    "    \"ConjunctionPhrases\",  # 9\n",
    "    \"Pronouns\",            #10\n",
    "    \"Intensifiers\",        #11\n",
    "    \"VerbParticles\",       #12  <-- NEW\n",
    "    \"DirectionalAdverbs\",  #13  <-- NEW\n",
    "    \"PleonasticSubjects\",  #14  <-- NEW\n",
    "    \"ClauseFinalAdjunct\"   #15  <-- NEW\n",
    "]\n",
    "\n",
    "def explain_example(i: int, top_m: int = 1):\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Sentence {i}: {sentences[i]}\")\n",
    "    print(f\"Gold consensus: {df.iloc[i]['consensus']}\")\n",
    "    print(f\"SENN prob: {oof_prob[i]:.3f}  → pred label: {y_pred_oof[i]}\")\n",
    "    gold = get_gold_label_tokens(i)\n",
    "    pred = get_predicted_label_tokens(i, top_m=top_m)\n",
    "    print(f\"Gold tokens: {gold}\")\n",
    "    print(f\"Predicted tokens: {pred}\")\n",
    "\n",
    "    # Show per-concept contributions\n",
    "    c_vec   = concept_matrix[i]\n",
    "    theta_i = oof_theta[i]\n",
    "    contrib = c_vec * theta_i\n",
    "    idx_sorted = sorted(range(len(contrib)), key=lambda k: -contrib[k])\n",
    "\n",
    "    print(\"\\nTop concept contributions (c_k * θ_k):\")\n",
    "    for k in idx_sorted[:5]:\n",
    "        span_tokens = [docs[i][j].text for j in sorted(all_roles[i][k])]\n",
    "        print(f\"  k={k:2d} ({role_names[k]:>18})  contrib={contrib[k]:+.4f}  span={span_tokens}\")\n",
    "explain_example(5, top_m=1)\n",
    "explain_example(54, top_m=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
